{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "mtj_tracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-c8RgH2qmOk"
   },
   "source": [
    "# Deep MTJ - automatic tracking of the muscel-tendon junction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9koqLI8hq7l6"
   },
   "source": [
    "This notebook shows how to use the MTJ tracking tool. Google Colab offers free online computation resources. You can track your own videos by uploading your video files (see menu on the left) and running the model online. It is also possible to run the tool on your local enviroment by installing the `setup.py` file (see GitHub repository; https://github.com/luuleitner/deepMTJ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfirUKeHsT-m"
   },
   "source": [
    "The MTJ tool can be directly installed from the GitHub repository using PIP."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kqxYardxqlkC"
   },
   "source": [
    "#!pip install git+https://github.com/luuleitner/deepMTJ"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkJ-eS4RscXw"
   },
   "source": [
    "For tracking the MTJ positions from multiple videos we can simple use the `track_videos` function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rDsuB5O7sKVp"
   },
   "source": [
    "from mtj_tracking.predict.predict import track_videos # main tracking function\n",
    "from mtj_tracking.data.loader import Frame, loadVideo, adjustFrame # helper for DeepMTJ\n",
    "from matplotlib import pyplot as plt # plotting function"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH7LdCCasoTU"
   },
   "source": [
    "We start by downloading a sample video from the Esaote instrument."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6mt-lDiqsTXm"
   },
   "source": [
    "#urlretrieve('', 'esaote_video.avi')"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elbdzS1os-bx"
   },
   "source": [
    "First we need to specify the region of interest within the video. For this we select the x/y-position and the width and height of the frame that we want to crop from video."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RT_lKUVPtVPL"
   },
   "source": [
    "frame = Frame((185, 128, 580, 290)) # x, y, width, height"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5r5XvyWtp1i"
   },
   "source": [
    "Let us check that we have selected the correct sub-frame by reading the video."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SZlJJ8aWt2zZ"
   },
   "source": [
    "video_id, video = loadVideo('esaote_video.avi') # returns the video id and a list of frames\n",
    "adjusted_video_frame = adjustFrame(video[0], frame, (128, 256)) # crops to specified frame\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(video[0]) # plot the first frame\n",
    "plt.title('Full Frame')\n",
    "plt.subplot(122)\n",
    "plt.imshow(adjusted_video_frame, cmap='gray') # plot the adjusted frame\n",
    "plt.title('Cropped Frame')\n",
    "plt.show()"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"esaote_video.avi\"\n",
      "[ERROR:0] global ../modules/videoio/src/cap.cpp (162) open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.5.2) ../modules/videoio/src/cap_images.cpp:253: error: (-5:Bad argument) CAP_IMAGES: can't find starting number (in the name of file): esaote_video.avi in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/tf/6fxjp1t57psb37scy8brr9dm0000gn/T/ipykernel_15458/3066965200.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mvideo_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvideo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloadVideo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'esaote_video.avi'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# returns the video id and a list of frames\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0madjusted_video_frame\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0madjustFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvideo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;36m128\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m256\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# crops to specified frame\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m121\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvideo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# plot the first frame\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTeOIX_ZzPr5"
   },
   "source": [
    "Alternatively we can also use one of the predefined frames. Note that all images are processed at 256x128 pixels. The aspect ratio of the specified frame should be the same (2:1).\n",
    "```\n",
    "Frame.ESAOTE = (185, 128, 580, 290)\n",
    "Frame.TELEMED = (88, 120, 446, 223)\n",
    "Frame.AIXPLORER = (200, 261, 1000, 500)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gv46GT2zr7U"
   },
   "source": [
    "Now we can track the MTJ in our video."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QvObq4pPzijj"
   },
   "source": [
    "result_df = track_videos(['esaote_video.avi'], Frame.ESAOTE)\n",
    "result_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51SYz45l4Ore"
   },
   "source": [
    "Let us check the result of the model by plotting the predicted MTJ position."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ETNCqgob4YvL"
   },
   "source": [
    "plt.imshow(adjusted_video_frame, cmap='gray') # plot the adjusted frame\n",
    "plt.scatter(result_df.x[0], result_df.y[0], color='red')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The same check can be performed for the full video sequence."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(video)):\n",
    "    last_video_frame = adjustFrame(video[i], frame, (128, 256)) # crops to specified frame\n",
    "    plt.imshow(last_video_frame, cmap='gray') # plot the adjusted frame\n",
    "    plt.axis('off')\n",
    "    plt.scatter(result_df.x[i], result_df.y[i], color='red')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwU163D8z5MU"
   },
   "source": [
    "The result can be also converted to the pixel coordinates of the original video."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f0h2hLdS0lLA"
   },
   "source": [
    "result_oc_df = track_videos(['esaote_video.avi'], Frame.ESAOTE, frame_coordinates=False)\n",
    "result_oc_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(video[0]) # plot the original frame\n",
    "plt.scatter(result_oc_df.x[0], result_oc_df.y[0], color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAn1rfF91MaR"
   },
   "source": [
    "The list contains the pixel coordinates for each frame of the specified videos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyUrztdC1S_o"
   },
   "source": [
    "You can upload your own videos and convert them using the computational resources from Colab. If you have to process more data you can activate a GPU environment. For this select Runtime --> Change runtime type --> Hardware acceleration --> GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlkVL0U81znf"
   },
   "source": [
    "To convert your own files, upload your videos and specify the list of video files in the `track_video` function.\n",
    "The result can be afterwards saved as a CSV file and downloaded."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l73icOY71SLm"
   },
   "source": [
    "result_df = track_videos(['<<your-video>>'], Frame.ESAOTE)\n",
    "result_df.to_csv('deep_mtj.csv')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}