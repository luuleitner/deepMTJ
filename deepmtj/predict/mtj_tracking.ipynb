{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mtj_tracking_v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-c8RgH2qmOk"
      },
      "source": [
        "# Deep MTJ - automatic tracking of the muscel-tendon junction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9koqLI8hq7l6"
      },
      "source": [
        "This notebook shows how to use the MTJ tracking tool. Google Colab offers free online computation resources. You can track your own videos by uploading your video files (see menu on the left) and running the model online. It is also possible to run the tool on your local enviroment by installing the `setup.py` file (see GitHub repository; https://github.com/luuleitner/deepMTJ).\n",
        "\n",
        "The first step when running in Colab is to go to \"Runtime\" and \"change runtime type\" under \"Hardware accelerator\" -> select \"GPU\" "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "zePcx8GJPysS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqxYardxqlkC"
      },
      "source": [
        "# deepMTJ can be directly installed from the GitHub repository using PIP.\n",
        "\n",
        "!pip install git+https://github.com/luuleitner/deepMTJ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDsuB5O7sKVp"
      },
      "source": [
        "# We need to import necessary packages into Colab. Don't worry to much about this cell of code\n",
        "# For tracking the MTJ positions from multiple videos we can simple use the `track_videos` function.\n",
        "\n",
        "from mtj_tracking.predict.predict import track_videos # main tracking function\n",
        "from mtj_tracking.data.loader import Frame, loadVideo, adjustFrame # helper for DeepMTJ\n",
        "from mtj_tracking.process.filter import pre_filter, hampel_filter # load filter for time series data\n",
        "from matplotlib import pyplot as plt # plotting function\n",
        "import numpy as np # array handeling\n",
        "from urllib.request import urlretrieve # for downloading the sample data\n",
        "from enum import Enum # Enum package to add unknown framecuts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download sample data"
      ],
      "metadata": {
        "id": "E2N2UOkzRXps"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mt-lDiqsTXm"
      },
      "source": [
        "# Download a sample video from an Esaote instrument.\n",
        "\n",
        "urlretrieve('https://storage.googleapis.com/deepmtj/IEEEtbme_testset_2021/deepMTJ_TS_v0001.avi', 'esaote_video.avi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare your data"
      ],
      "metadata": {
        "id": "yry95c3PRiBs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elbdzS1os-bx"
      },
      "source": [
        "First, we need to specify the region of interest within the video. We select the x/y-position and the width and height of the frame that we want to crop from the video (x, y, width, height). The proportions of width/height need to have a ratio of 2/1.\n",
        "\n",
        "We provide the following predefined crops:\n",
        "\n",
        "```\n",
        "Frame.ESAOTE = (185, 128, 580, 290)\n",
        "Frame.TELEMED = (88, 120, 446, 223)\n",
        "Frame.AIXPLORER = (200, 261, 1000, 500)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you are not satisfied with any of the predefined crops just add your own:\n",
        "# We have added the Ultrasonix ultrasound below.\n",
        "\n",
        "class CustomFrame(Enum):\n",
        "     USX_ST = (113, 185, 500, 200)  # Ultrasonix SonixTouch\n",
        "     USX_RP = (126, 250, 490, 245)  # Ultrasonix RP\n",
        "\n",
        "     #--> to define your own crop configure and uncomment the line below --->\n",
        "     # YOUR_CROP_NAME = (x, y, width, height) # make sure that the proportions of width/height are 2/1"
      ],
      "metadata": {
        "id": "h5bLv7MkUKSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT_lKUVPtVPL"
      },
      "source": [
        "frame = Frame.ESAOTE # apply the defined crop\n",
        "\n",
        "#--> if you defined your own crop configure and uncomment the line below ---> \n",
        "# frame = CustomFrame.YOUR_CROP_NAME "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5r5XvyWtp1i"
      },
      "source": [
        "Let us check that we have selected the correct sub-frame by reading the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZlJJ8aWt2zZ"
      },
      "source": [
        "video_id, video = loadVideo('esaote_video.avi') # returns the video id and a list of frames\n",
        "adjusted_video_frame = adjustFrame(video[0], frame, (128, 256)) # crops to specified frame\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(video[0]) # plot the first frame\n",
        "plt.title('Full Frame')\n",
        "plt.subplot(122)\n",
        "plt.imshow(adjusted_video_frame, cmap='gray') # plot the adjusted frame\n",
        "plt.title('Cropped Frame')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Track the MTJ in single video"
      ],
      "metadata": {
        "id": "dHfZc7_JZLE6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvObq4pPzijj"
      },
      "source": [
        "# Now we can track the MTJ in our video.\n",
        "\n",
        "result_df = track_videos(['esaote_video.avi'], frame)\n",
        "result_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5O0OQBG_aBRm"
      },
      "source": [
        "# Plot the tracked results of the video sequence\n",
        "\n",
        "for i in range(len(video)):\n",
        "    last_video_frame = adjustFrame(video[i], frame, (128, 256)) # crops to specified frame\n",
        "    plt.imshow(last_video_frame, cmap='gray') # plot the adjusted frame\n",
        "    plt.axis('off')\n",
        "    plt.scatter(result_df.x[i], result_df.y[i], color='red')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert labels to full resolution and save Predictions"
      ],
      "metadata": {
        "id": "1BvGaUeVakbq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0h2hLdS0lLA"
      },
      "source": [
        "# The result can also be converted to the pixel coordinates of the original video frame\n",
        "\n",
        "result_oc_df = track_videos(['esaote_video.avi'], frame, frame_coordinates=False)\n",
        "result_oc_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Uw9CyJBMaBRn"
      },
      "source": [
        "# Plot the first video frame in full resolution\n",
        "\n",
        "plt.imshow(video[0]) # plot the original frame\n",
        "plt.scatter(result_oc_df.x[0], result_oc_df.y[0], color='red')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l73icOY71SLm"
      },
      "source": [
        "# Download the csv file using the Colab file explorer\n",
        "result_df.to_csv('deep_mtj.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Track MTJ in multiple video files"
      ],
      "metadata": {
        "id": "AIrDS4Ewg5Mm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlkVL0U81znf"
      },
      "source": [
        "To convert your own files, upload your videos and specify the list of video files in the `track_video` function.\n",
        "The result can be afterwards saved as a CSV file and downloaded."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = track_videos(['<<your-video-1>>', '<<your-video-2>>'], frame)\n",
        "result_df.to_csv('deep_mtj.csv') # Save the tracking results to a csv file"
      ],
      "metadata": {
        "id": "1swRe8H2g7XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter timeseries"
      ],
      "metadata": {
        "id": "08M6BgVRaVJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These filter routines are just a standard template. You may need to switch the individual stages on and off or adjust the parameters depending on your data and recording quality."
      ],
      "metadata": {
        "id": "k-VanlCQi9Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If your data has NaN values (no prediction) this line might be helpfull to interpolate over missing sample points\n",
        "\n",
        "result_df_interpolated = result_df[['x','y']].interpolate(method='linear', axis=0, limit = 20).ffill().bfill()"
      ],
      "metadata": {
        "id": "Ikbig3WpehsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If your predictions are noisy we provide two types of filters to get rid of outliers\n",
        "\n",
        "# Apply Prefilter\n",
        "result_df_prefiltered = pre_filter(result_df_interpolated)\n",
        "\n",
        "# Apply Hampel Filter\n",
        "result_df_filtered = np.column_stack(([hampel_filter(result_df_prefiltered.iloc[:, col], 10, n_sigmas=2) for col in range(result_df_prefiltered.shape[1])]))"
      ],
      "metadata": {
        "id": "COOngSDkehiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot your filter results here\n",
        "\n",
        "fig = plt.figure(figsize=(6, 7), dpi=300)\n",
        "ax_1 = fig.add_subplot(211)\n",
        "\n",
        "# MTJ x-coordinate\n",
        "ax_1.plot(result_df['x'], c='g', label='raw') # raw prediction\n",
        "ax_1.plot(result_df_interpolated['x'], c='b', label='NaN interp.') # interpolated prediction\n",
        "ax_1.plot(result_df_filtered[:, 0], c='r', label='filtered') # filterd prediction\n",
        "ax_1.xaxis.set_visible(False)\n",
        "ax_1.set_ylabel('MTU x-position')\n",
        "ax_1.legend(loc='lower left')\n",
        "ax_1.set_title('MTJ x-coordinate')\n",
        "# MTJ y-coordinate\n",
        "ax_2 = fig.add_subplot(212)\n",
        "ax_2.plot(result_df['y'], c='g', label='raw') # raw prediction\n",
        "ax_2.plot(result_df_interpolated['y'], c='b', label='NaN interp.') # interpolated prediction\n",
        "ax_2.plot(result_df_filtered[:, 1], c='r', label='filtered') # filterd prediction\n",
        "ax_2.xaxis.set_visible(False)\n",
        "ax_2.set_ylabel('MTJ y-position')\n",
        "ax_2.legend(loc='lower left')\n",
        "ax_2.set_title('MTJ y-coordinate')\n",
        "#\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XbwgGbeOhgBp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}